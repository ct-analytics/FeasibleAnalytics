<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Machine Learning | Christopher Teixeira</title>
    <link>/tags/machine-learning/</link>
      <atom:link href="/tags/machine-learning/index.xml" rel="self" type="application/rss+xml" />
    <description>Machine Learning</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>© 2019</copyright><lastBuildDate>Mon, 02 Sep 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Machine Learning</title>
      <link>/tags/machine-learning/</link>
    </image>
    
    <item>
      <title>Categorizing Pitches</title>
      <link>/post/20190902_predicting_pitch_types/</link>
      <pubDate>Mon, 02 Sep 2019 00:00:00 +0000</pubDate>
      <guid>/post/20190902_predicting_pitch_types/</guid>
      <description>


&lt;div id=&#34;data-discussion&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Data discussion&lt;/h1&gt;
&lt;p&gt;My customary evening activity is listening to the NESN commentary during a Red Sox game. During one particular game, a pitcher threw a pitch they suspected was a screwball. Over the next few minutes, they discussed the the prevalence of screwballs in today’s game versus other pitches that could appear like screwballs. I took this as an opportunity to evaluate the movement on pitches and see if any in fact might be “more screwball-like”.&lt;/p&gt;
&lt;p&gt;Using data provided by TruMedia for a hackathon, I looked into using their pitch-by-pitch data to see if this was even possible.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;pitchType&lt;/em&gt;
* CH - Changeup
* CU - Curveball
* FA - Fastball
* FT - Two Seamer
* FF - Four Seamer
* FC - Cutter
* SL - Slider
* FS - Splitter
* SI - Sinker
* FO - Forkball
* KN - Knuckleball
* KC - Knuckle Curve
* SC - Screwball
* GY - Gyroball
* EP - Eephus
* PO - Pitchout
* IN - Intentional Ball
* AB - Automatic Ball
* AS - Automatic Strike
* UN - Unknown&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;ggplot(df %&amp;gt;% group_by(pitchType) %&amp;gt;% count() %&amp;gt;% arrange(desc(n)), aes(x=reorder(pitchType,-n),y=n)) +
  geom_bar(stat=&amp;quot;identity&amp;quot;) +
  geom_text(aes(label = ks(n), y=n), vjust = -.5, stat=&amp;quot;identity&amp;quot;) +
  scale_y_continuous(labels=ks) + 
  ylab(&amp;quot;Number of Pitches&amp;quot;) +
  xlab(&amp;quot;Pitch Type&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/20190902_predicting_pitch_types_files/figure-html/data_overview-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;removePitchTypes &amp;lt;- c(&amp;quot;PO&amp;quot;,&amp;quot;IN&amp;quot;,&amp;quot;AB&amp;quot;,&amp;quot;AS&amp;quot;,&amp;quot;FA&amp;quot;,&amp;quot;UN&amp;quot;)
df &amp;lt;- filter(df,!(pitchType %in% removePitchTypes))
num.pitch.types &amp;lt;- df %&amp;gt;% select(pitchType) %&amp;gt;% distinct() %&amp;gt;% count() %&amp;gt;% pull()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Given that, we’re going to remove some pitch types. The pitch types we remove fall under two categories:
1) “automatic” pitches like pitch outs, intentional balls
2) uncommon pitches like “unknown” and “fastballs”&lt;/p&gt;
&lt;div id=&#34;splitting-the-data-for-validation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Splitting the data for validation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;set.seed(4567)
df_split &amp;lt;- initial_split(df, prop = 0.75, strata = &amp;quot;pitchType&amp;quot;)

response_train &amp;lt;- ggplot(training(df_split),aes(x=pitchType, group=1)) +
  geom_bar(aes(y =..prop..), stat=&amp;quot;count&amp;quot;, width=.75) +
  geom_text(aes(label = scales::percent(..prop..), y=..prop..), vjust = -.5, stat=&amp;quot;count&amp;quot;) +
  scale_y_continuous(labels=scales::percent) +
  ylab(&amp;quot;Relative frequencies&amp;quot;) +
  xlab(&amp;quot;Pitch Type&amp;quot;)
response_test &amp;lt;- ggplot(testing(df_split),aes(x=pitchType, group=1)) +
  geom_bar(aes(y =..prop.., group=1), stat=&amp;quot;count&amp;quot;, width=.75) +
  geom_text(aes(label = scales::percent(..prop..), y=..prop..), stat= &amp;quot;count&amp;quot;, vjust = -.5) +
  scale_y_continuous(labels=scales::percent) +
  ylab(&amp;quot;Relative frequencies&amp;quot;) +
  xlab(&amp;quot;Pitch Type&amp;quot;)
gridExtra::grid.arrange(response_train, response_test)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/20190902_predicting_pitch_types_files/figure-html/data_split-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;recipe-for-processing-data&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Recipe for processing data&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Upsample minority class
majority.class.amount &amp;lt;- df_split %&amp;gt;%
  training() %&amp;gt;%
  group_by(pitchType) %&amp;gt;%
  summarize(n=n()) %&amp;gt;%
  arrange(desc(n)) %&amp;gt;%
  slice(1) %&amp;gt;%
  pull()

minority.class.amount &amp;lt;- 1000

df_recipe &amp;lt;- df_split %&amp;gt;%
  training() %&amp;gt;%
  recipe(pitchType ~ . - pitcherId) %&amp;gt;%
  # step_num2factor(pitcherId) %&amp;gt;%
  step_string2factor(pitcherHand, pitchType) %&amp;gt;%
  update_role(pitcherId, new_role = &amp;quot;id variable&amp;quot;) %&amp;gt;%
  step_upsample(pitchType, ratio=minority.class.amount/majority.class.amount) %&amp;gt;%
  step_center(all_predictors(), -all_outcomes(), -all_nominal()) %&amp;gt;%
  step_scale(all_predictors(), -all_outcomes(), -all_nominal()) %&amp;gt;%
  # step_corr(all_numeric(), - all_outcomes(), threshold = 0.5) %&amp;gt;%
  step_dummy(all_nominal(), -all_outcomes()) %&amp;gt;%
  step_naomit(px) %&amp;gt;%
  prep(retain=TRUE)

df_recipe&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Data Recipe&lt;/p&gt;
&lt;p&gt;Inputs:&lt;/p&gt;
&lt;pre&gt;&lt;code&gt;    role #variables&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;id variable 1
outcome 1
predictor 16&lt;/p&gt;
&lt;p&gt;Training data contained 536894 data points and no missing data.&lt;/p&gt;
&lt;p&gt;Operations:&lt;/p&gt;
&lt;p&gt;Factor variables from pitcherHand, pitchType [trained]
Up-sampling based on pitchType [trained]
Centering for releaseVelocity, spinRate, spinDir, px, … [trained]
Scaling for releaseVelocity, spinRate, spinDir, px, … [trained]
Dummy variables from pitcherHand [trained]
Removing rows with NA values in px&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_training &amp;lt;- juice(df_recipe)
df_testing &amp;lt;- df_recipe %&amp;gt;%
  bake(testing(df_split))&lt;/code&gt;&lt;/pre&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;a-first-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;A first model&lt;/h1&gt;
&lt;p&gt;Our goal is to build a model that examines pitch types and whether they are categorized by pitch movement. The inspiration for this was built upon a comment that “screwballs” aren’t thrown anymore. While pitches can be categorized by the combination of how the pitcher holds the baseball with the arm movements, the behavior of the ball itself can vary slightly and begs the question, “do some two seam fastballs act like screwballs?” We’ll generalize this and understand if there are certain pitches that behave like others.&lt;/p&gt;
&lt;div id=&#34;null-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Null model&lt;/h2&gt;
&lt;p&gt;In order to appreciate the power of our model, let’s first create a null model to understand a baseline predictability. Parsnip has a function for figuring this out, although some basic data manipulation can come to the same conclusion. The null model essentially just says “always guess the majority class” (for classification models).&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Using data manipulation and dplyr
majority.class.accuracy &amp;lt;- df %&amp;gt;% group_by(pitchType) %&amp;gt;% summarize(n=n()) %&amp;gt;% mutate(pct=n/sum(n)) %&amp;gt;% arrange(desc(n)) %&amp;gt;% slice(1) %&amp;gt;% select(pct) %&amp;gt;% pull()

# Using parsnip::nullmodel
null.model &amp;lt;- nullmodel(y=factor(df$pitchType))
null.model.accuracy &amp;lt;- null.model$pct %&amp;gt;% as_tibble %&amp;gt;% filter(y==null.model$value) %&amp;gt;% select(n) %&amp;gt;% pull()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Randomly guessing the majority class would give us an accuracy of 34.8%.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;improved-naive-model&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Improved Naive model&lt;/h2&gt;
&lt;p&gt;We can do slightly better than that if we build a model based on the pitcher. This model will weight for what a pitcher normally throws.&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Naive model
df_rf_naive &amp;lt;- rand_forest(trees = 100, mode = &amp;quot;classification&amp;quot;) %&amp;gt;%
  set_engine(&amp;quot;randomForest&amp;quot;, importance=T, localImp = T) %&amp;gt;%
  fit(pitchType ~ pitcherId, data = df_training)

# Baseline results
baseline.results &amp;lt;- predict(df_rf_naive, df_testing, type = &amp;quot;prob&amp;quot;) %&amp;gt;%
  bind_cols(predict(df_rf_naive, df_testing)) %&amp;gt;%
  bind_cols(select(df_testing, pitchType)) %&amp;gt;%
  metrics(pitchType, .pred_CH:.pred_SL, estimate = .pred_class, options=c(&amp;quot;quiet&amp;quot;=T))

baseline.results %&amp;gt;% knitr::kable(digits=4)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;.metric&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;.estimator&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;.estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;accuracy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;multiclass&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4629&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;kap&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;multiclass&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.2902&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mn_log_loss&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;multiclass&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.1878&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;roc_auc&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;hand_till&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7112&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;baseline.accuracy &amp;lt;- baseline.results %&amp;gt;% filter(.metric==&amp;quot;accuracy&amp;quot;) %&amp;gt;% select(.estimate) %&amp;gt;% pull&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;Our true baseline is now 46.3% that we will use in measuring performance of our model going forward.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;building-a-full-model&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Building a full model&lt;/h1&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;# Full model
df_rf &amp;lt;- rand_forest(trees = 100, mode = &amp;quot;classification&amp;quot;) %&amp;gt;%
  set_engine(&amp;quot;randomForest&amp;quot;, importance=T, localImp = T) %&amp;gt;%
  fit(pitchType ~ . - pitcherId, data = df_training)

df_rf&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## parsnip model object
## 
## 
## Call:
##  randomForest(x = as.data.frame(x), y = y, ntree = ~100, importance = ~T,      localImp = ~T) 
##                Type of random forest: classification
##                      Number of trees: 100
## No. of variables tried at each split: 4
## 
##         OOB estimate of  error rate: 8.22%
## Confusion matrix:
##       CH    CU   EP    FC     FF  FO   FS    FT   KC   KN   SC    SI    SL
## CH 52303    17    0    49    453   2  193   403    1   24    5   633   438
## CU    28 40711    7    12      5   0    2     0  348   19    0     0  2012
## EP     0     0 1000     0      0   0    0     0    0    0    0     0     0
## FC    89    15    0 24372   1535   0    2    14    0    0    0    12  2727
## FF   477     2    0   929 179915   0   14  3922    0    6    0  1547   329
## FO    38     1    0     0     12 928    0    12    0    0    0     9     0
## FS  1962     4    0    14     50   1 5660    27    0    4    0    67   116
## FT   745     4    0     4   6366   2    6 55590    0    0    0  3288    19
## KC    14  1594    0     3      0   0    2     0 7134    1    0     1   672
## KN    42    61    0     0      0   0    2     0    2 2243    0     0    21
## SC     0     0    0     0      0   0    0     0    0    0 1000     0     0
## SI   788     0    0     7   3631   1    9  4747    0    0    0 45316    24
## SL   388  1350    0  1293    377   0   35    11  188    5    0    23 78757
##    class.error
## CH  0.04068157
## CU  0.05639255
## EP  0.00000000
## FC  0.15274977
## FF  0.03861260
## FO  0.07200000
## FS  0.28399747
## FT  0.15803344
## KC  0.24275555
## KN  0.05398566
## SC  0.00000000
## SI  0.16886452
## SL  0.04452425&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full.model.results &amp;lt;- predict(df_rf, df_testing, type = &amp;quot;prob&amp;quot;) %&amp;gt;%
  bind_cols(predict(df_rf, df_testing)) %&amp;gt;%
  bind_cols(select(df_testing, pitchType)) %&amp;gt;%
  metrics(pitchType, .pred_CH:.pred_SL, estimate = .pred_class, options=c(&amp;quot;quiet&amp;quot;=T))

full.model.results %&amp;gt;% knitr::kable(digits=4)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;.metric&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;.estimator&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;.estimate&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;accuracy&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;multiclass&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7811&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;kap&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;multiclass&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.7266&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;mn_log_loss&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;multiclass&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5613&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;roc_auc&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;hand_till&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.9688&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;full.model.accuracy &amp;lt;- full.model.results %&amp;gt;% filter(.metric==&amp;quot;accuracy&amp;quot;) %&amp;gt;% select(.estimate) %&amp;gt;% pull&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;A simple first attempt at building a model results in an accuracy of 78.1%, or 1.7 times better than our baseline model.&lt;/p&gt;
&lt;div id=&#34;model-interpretation&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Model interpretation&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results &amp;lt;- df_rf %&amp;gt;%
  predict(df_testing) %&amp;gt;%
  bind_cols(df_testing) %&amp;gt;%
  select(pitcherId,actual=pitchType, predicted=.pred_class)

# Permutation based importance
cbind(rownames(df_rf$fit$importance), df_rf$fit$importance) %&amp;gt;%
  as_tibble() %&amp;gt;%
  select(predictor=V1, MeanDecreaseAccuracy)   %&amp;gt;%
  mutate(MeanDecreaseAccuracy=as.numeric(MeanDecreaseAccuracy)) %&amp;gt;%
  arrange(desc(MeanDecreaseAccuracy)) %&amp;gt;%
  head()&lt;/code&gt;&lt;/pre&gt;
&lt;pre&gt;&lt;code&gt;## # A tibble: 6 x 2
##   predictor       MeanDecreaseAccuracy
##   &amp;lt;chr&amp;gt;                          &amp;lt;dbl&amp;gt;
## 1 spinDir                        0.288
## 2 az                             0.258
## 3 ax                             0.253
## 4 vy0                            0.248
## 5 releaseVelocity                0.244
## 6 x0                             0.190&lt;/code&gt;&lt;/pre&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_probs &amp;lt;- df_rf %&amp;gt;%
  predict(df_testing, type = &amp;quot;prob&amp;quot;) %&amp;gt;%
  bind_cols(df_testing)

df_probs %&amp;gt;%
  roc_curve(pitchType, .pred_CH:.pred_SL, options=c(&amp;quot;quiet&amp;quot;=TRUE)) %&amp;gt;%
  autoplot()&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/20190902_predicting_pitch_types_files/figure-html/results_roc-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;conf_mat(results, truth = actual, estimate = predicted)[[1]] %&amp;gt;%
  prop.table(2) %&amp;gt;%
  round(2) %&amp;gt;%
  as_tibble() %&amp;gt;%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = scales::percent(n, accuracy=1), alpha = n), size = 6) +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  labs(
    title = &amp;quot;Confusion matrix&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/20190902_predicting_pitch_types_files/figure-html/results_confusionmatrix-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div id=&#34;analysis&#34; class=&#34;section level1&#34;&gt;
&lt;h1&gt;Analysis&lt;/h1&gt;
&lt;div id=&#34;which-pitch-is-often-misclassified&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Which pitch is often misclassified?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results %&amp;gt;%
  mutate(correct=if_else(actual==predicted,1,0)) %&amp;gt;%
  group_by(actual) %&amp;gt;%
  summarize(n = n(),
            wrong = n - sum(correct)) %&amp;gt;%
  mutate(pct = wrong / n) %&amp;gt;%
  arrange(desc(pct)) %&amp;gt;%
  left_join(pitchtypes,by=c(&amp;quot;actual&amp;quot;=&amp;quot;pitchType&amp;quot;)) %&amp;gt;%
  mutate(Percent=percent(pct)) %&amp;gt;%
  select(`Pitch Type`=pitch, `Number of Pitches`=n, `Incorrect Category`=wrong, Percent) %&amp;gt;%
  knitr::kable()&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Pitch Type&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Number of Pitches&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Incorrect Category&lt;/th&gt;
&lt;th align=&#34;left&#34;&gt;Percent&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Forkball&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;146&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;143&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;97.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Splitter&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2665&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1993&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;74.8%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Knuckle&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3109&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2009&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;64.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Sinker&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;18339&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;8227&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;44.9%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Two&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21979&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9148&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;41.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Cutter&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;9708&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;4031&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;41.5%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Screwball&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;25&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;10&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;40.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Eephus&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;21&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;27.3%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Curveball&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;14577&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;2070&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14.2%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Knuckleball&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;758&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;107&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;14.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Slider&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;27619&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;3213&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11.6%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Changeup&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;17878&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;1979&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;11.1%&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Four&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;62083&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;6226&lt;/td&gt;
&lt;td align=&#34;left&#34;&gt;10.0%&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;which-pitcher-often-has-his-pitches-misclassified&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Which pitcher often has his pitches misclassified?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;results %&amp;gt;%
  mutate(correct=if_else(actual==predicted,1,0)) %&amp;gt;%
  group_by(pitcherId) %&amp;gt;%
  summarize(n = n(),
            wrong = n - sum(correct)) %&amp;gt;%
  mutate(pct = wrong / n) %&amp;gt;%
  arrange(desc(pct)) %&amp;gt;%
  left_join(pitchers) %&amp;gt;%
  filter(n&amp;gt;100) %&amp;gt;%
  select(Pitcher=pitcher, `Number of Pitches`=n, `Incorrect Category`=wrong, Percent=pct) %&amp;gt;%
  slice(1:20) %&amp;gt;%
  knitr::kable(digits=4)&lt;/code&gt;&lt;/pre&gt;
&lt;table&gt;
&lt;thead&gt;
&lt;tr class=&#34;header&#34;&gt;
&lt;th align=&#34;left&#34;&gt;Pitcher&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Number of Pitches&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Incorrect Category&lt;/th&gt;
&lt;th align=&#34;right&#34;&gt;Percent&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;
&lt;tbody&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Jose Veras&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;256&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;169&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6602&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Ross Wolf&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;175&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;111&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6343&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Darin Downs&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;138&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;83&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.6014&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Corey Kluber&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;539&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;320&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5937&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Mitchell Boggs&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;123&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;73&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5935&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Brandon Cumpton&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;122&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;72&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5902&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Michael Kirkman&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;108&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;63&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5833&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Lucas Harrell&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;710&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;398&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5606&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Brett Cecil&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;230&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;127&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5522&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Tanner Roark&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;176&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;96&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5455&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Luis Ayala&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;145&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;78&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5379&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Derek Holland&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;837&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;436&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5209&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Tyler Cloyd&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;262&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;135&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5153&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Bryan Morris&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;238&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;121&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5084&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;David Hernandez&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;256&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;130&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.5078&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Travis Blackley&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;211&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;105&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4976&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;P.J. Walters&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;155&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;77&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4968&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Roy Halladay&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;285&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;141&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4947&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;odd&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Brandon League&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;250&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;121&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4840&lt;/td&gt;
&lt;/tr&gt;
&lt;tr class=&#34;even&#34;&gt;
&lt;td align=&#34;left&#34;&gt;Scott Kazmir&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;674&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;323&lt;/td&gt;
&lt;td align=&#34;right&#34;&gt;0.4792&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div id=&#34;does-the-ability-of-categorizing-pitch-types-changes-over-time&#34; class=&#34;section level2&#34;&gt;
&lt;h2&gt;Does the ability of categorizing pitch types changes over time?&lt;/h2&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;df_additional &amp;lt;- df_recipe %&amp;gt;%
  bake(df.future)

ggplot(df_additional %&amp;gt;% group_by(pitchType) %&amp;gt;% count() %&amp;gt;% arrange(desc(n)), aes(x=reorder(pitchType,-n),y=n)) +
  geom_bar(stat=&amp;quot;identity&amp;quot;) +
  geom_text(aes(label = ks(n), y=n), vjust = -.5, stat=&amp;quot;identity&amp;quot;) +
  scale_y_continuous(labels=ks) + 
  ylab(&amp;quot;Number of Pitches&amp;quot;) +
  xlab(&amp;quot;Pitch Type&amp;quot;)&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/20190902_predicting_pitch_types_files/figure-html/analysis_3-1.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;pre class=&#34;r&#34;&gt;&lt;code&gt;future.performance &amp;lt;- predict(df_rf, df_additional, type = &amp;quot;prob&amp;quot;) %&amp;gt;%
  bind_cols(predict(df_rf, df_additional)) %&amp;gt;%
  bind_cols(select(df_additional, pitchType)) %&amp;gt;%
  metrics(pitchType, .pred_CH:.pred_SL, estimate = .pred_class, options=c(&amp;quot;quiet&amp;quot;=T)) %&amp;gt;% 
  knitr::kable(digits=4)

future.results &amp;lt;- df_rf %&amp;gt;%
  predict(df_additional) %&amp;gt;%
  bind_cols(df_additional) %&amp;gt;%
  select(pitcherId,actual=pitchType, predicted=.pred_class)

conf_mat(future.results, truth = actual, estimate = predicted)[[1]] %&amp;gt;%
  prop.table(2) %&amp;gt;%
  round(2) %&amp;gt;%
  as_tibble() %&amp;gt;%
  ggplot(aes(Prediction, Truth, alpha = n)) +
  geom_tile(show.legend = FALSE) +
  geom_text(aes(label = scales::percent(n, accuracy=1), alpha = n), size = 6) +
  theme(legend.position = &amp;quot;none&amp;quot;) +
  labs(
    title = &amp;quot;Confusion matrix&amp;quot;
  )&lt;/code&gt;&lt;/pre&gt;
&lt;p&gt;&lt;img src=&#34;/post/20190902_predicting_pitch_types_files/figure-html/analysis_3-2.png&#34; width=&#34;672&#34; /&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>State Engagement to Address Opioid Overprescribing and Misuse</title>
      <link>/project/state-engagement-to-address-opioid-overprescribing-and-misuse/</link>
      <pubDate>Tue, 11 Sep 2018 00:00:00 +0000</pubDate>
      <guid>/project/state-engagement-to-address-opioid-overprescribing-and-misuse/</guid>
      <description>&lt;p&gt;To be filled in later.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predicting Pitch Types</title>
      <link>/project/predicting-pitch-types/</link>
      <pubDate>Wed, 01 Mar 2017 00:00:00 +0000</pubDate>
      <guid>/project/predicting-pitch-types/</guid>
      <description>&lt;p&gt;TruMedia Networks sponsored their 2nd Baseball Analytics Hackathon to bring together some of sport&amp;rsquo;s brightest developers and analysts to see what projects and analysis they can create. Providing pitch data over the previous three years, I took the opportunity to explore the ability to predict the next pitch type. The link for this project walks through my analysis in R using a multinomial logistic regression model to predict pitch types for Jon Lester.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Predictive Analytics in Child Welfare</title>
      <link>/project/predictive-analytics-child-welfare/</link>
      <pubDate>Mon, 01 Aug 2016 00:00:00 +0000</pubDate>
      <guid>/project/predictive-analytics-child-welfare/</guid>
      <description>&lt;p&gt;Lead a small team that interviewed several child welfare agencies to understand their progress in utilizing predictive analytics. This environmental scan resulted in two publicly released documents hosted on the Department of Health and Human Services Assistant Secretary for Planning and Evaluation website.&lt;/p&gt;

&lt;p&gt;Separately, I led a small team that brought together six government agencies to analyze data around children in foster care to understand how their experiences impact their ability to lead health and independent lives. This involved working directly with a state to obtain and analyze their data using predictive analytics.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Children at Risk Research</title>
      <link>/project/children-at-risk-research/</link>
      <pubDate>Tue, 01 Dec 2015 00:00:00 +0000</pubDate>
      <guid>/project/children-at-risk-research/</guid>
      <description>&lt;p&gt;The Children at Risk research project looks at which information is important at determining which children under the age of ten are at higher risk for fatality due to abuse and neglect. Leading a small team, we&amp;rsquo;ve collected data from multiple parts of a local Health and Human Services Agency to bring together and understand some of the data quality issues that might exist in other HHS agencies. We use R (specifically the CARET library) to identify which factors are the most important in determining children who are at higher risk due to fatality. Using this information, we hope to design a data visualization tool that will help caseworkers identify those children at higher risk of fatality due to abuse and neglect.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Real Time Predictive Modeling</title>
      <link>/project/realtime-predictive-modeling/</link>
      <pubDate>Wed, 01 Jan 2014 00:00:00 +0000</pubDate>
      <guid>/project/realtime-predictive-modeling/</guid>
      <description>&lt;p&gt;Worked directly with a client to design data sources that allow for real time modeling and scoring. Led a team of statisticians to consolidate knowledge and design best practices in advanced modeling techniques for near real time model building.&lt;/p&gt;

&lt;p&gt;Designed a methodology to detect and predict client behavior patterns. Results of this methodology are intended to influence real-time marketing decisions to improve response rates.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>MLB Player Similarity</title>
      <link>/project/mlb-player-similarity/</link>
      <pubDate>Sat, 01 Jun 2013 00:00:00 +0000</pubDate>
      <guid>/project/mlb-player-similarity/</guid>
      <description>&lt;p&gt;Using a combination of dynamic programming and social network analysis, I compare a player&amp;rsquo;s career stats against other players to figure out who are the most similar. After determining which players are similar, I use various social network analysis techniques to be able to cluster and categorize players.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Sentiment Analysis for specific Brand/Products</title>
      <link>/project/sentiment-analysis/</link>
      <pubDate>Tue, 01 Jan 2013 00:00:00 +0000</pubDate>
      <guid>/project/sentiment-analysis/</guid>
      <description>&lt;p&gt;Analyze social media (Twitter) to determine sentiment around a client&amp;rsquo;s brand and specific products. Using R, analyzed tweets to determine shifts in sentiment over time about a client&amp;rsquo;s brand and general effectiveness of customer service. Produced visualizations through R and Tableau to help executives understand the sentiment analysis results.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Customer Attrition Analysis</title>
      <link>/project/customer-attrition-analysis/</link>
      <pubDate>Sat, 01 Dec 2012 00:00:00 +0000</pubDate>
      <guid>/project/customer-attrition-analysis/</guid>
      <description>&lt;p&gt;I worked with team members to build a Bayesian Belief Network (BBN) on large data sources in Netezza to predict the likelihood of a person closing an account with our client. I compared the BBN model results against Logistic Regression to determine best modeling approach. The results showed that the Logistic Regression approach provided more accurate results, but required more resources to get that result.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
